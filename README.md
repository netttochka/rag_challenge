RAG Question Answering Pipeline

Описание проекта
Проект реализует Retrieval-Augmented Generation (RAG) пайплайн для автоматического ответа на вопросы на основе PDF-документов. Решение принимает список вопросов и заранее извлечённые фрагменты из документов,
формирует контекст и с помощью LLM извлекает фактологические ответы строго из предоставленного текста. Результатом работы является JSON-файл, пригодный для автоматической проверки.

Архитектура решения
Входные данные
questions.json — список вопросов
retrieved.jsonl — результаты retrieval (PDF, страницы, текстовые фрагменты)
data/pdfs — PDF-документы, по которым производится поиск

Обработка
формирование компактного контекста из топ-фрагментов
запрос к языковой модели со строгими инструкциями
парсинг и валидация JSON-ответа
нормализация ответа в соответствии с типом вопроса

Выход
итоговый JSON-файл сабмита с ответами и ссылками на источники

Структура проекта
.
├── data/
│ ├── questions.json
│ ├── retrieved.jsonl
│ └── pdfs/
├── main.py
├── motovilova_v61.json
└── README.md

Формат вопросов
Каждый вопрос имеет тип kind, который определяет формат ответа и значение по умолчанию, если ответ не найден в контексте.

boolean — логическое значение, по умолчанию false
number — числовое значение, по умолчанию 0
name — строка, по умолчанию пустая строка
names — строка, по умолчанию пустая строка

Используемая модель
В проекте используется модель gpt-5-nano с температурой 0 для обеспечения детерминированного и стабильного вывода. Модель получает строго ограниченный контекст и обязана возвращать валидный JSON.
Ключевые особенности реализации
Модель обязана возвращать только JSON с единственным полем value
При отсутствии ответа в контексте используется строго заданное значение по умолчанию
Реализован безопасный парсер JSON, устойчивый к некорректному выводу модели
Добавлен retry-механизм, повторно запрашивающий модель в случае невалидного ответа
Для повышения groundedness в ответ добавляются ссылки на несколько PDF-источников
Все ответы нормализуются в соответствии с типом вопроса

Запуск проекта
Для запуска достаточно выполнить:
python main.py

После выполнения будет сгенерирован файл motovilova_v9.json, готовый для загрузки в систему оценки.

Формат выходного файла
Файл сабмита содержит email, имя сабмита и массив ответов. Каждый ответ включает текст вопроса, значение и ссылки на PDF-источники с указанием sha1-хэша документа и номера страницы.

Оптимизация качества
В проекте применены следующие приёмы повышения качества:
строгие дефолтные значения вместо N/A
детерминированный вывод модели
ограничение и структурирование контекста
повторная валидация и нормализация ответов
использование нескольких источников для подтверждения ответа

Итог
Решение ориентировано на максимальную корректность, воспроизводимость и соответствие требованиям автоматической проверки, а не на генерацию произвольных текстовых ответов.
